
import time
import streamlit as st
import os
import cv2
import numpy as np
import pandas as pd
import random
import struct
import mlflow
import matplotlib.pyplot as plt
from streamlit_drawable_canvas import st_canvas
from sklearn.model_selection import train_test_split
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split, StratifiedKFold
from tensorflow import keras

def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is not None:
        img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
        img = img.resize((28, 28)).convert("L")  # Resize vÃ  chuyá»ƒn thÃ nh grayscale
        img = np.array(img, dtype=np.float32) / 255.0  # Chuáº©n hÃ³a vá» [0, 1]
        return img.reshape(1, -1)  # Chuyá»ƒn thÃ nh vector 1D
    return None


def load_mnist_data():
    X = np.load("data/X.npy")
    y = np.load("data/y.npy")
    return X, y




def data_preparation():
    st.title("Chia dá»¯ liá»‡u Train/Test")
    
    # Táº¡o cÃ¡c biáº¿n Ä‘á»ƒ lÆ°u dá»¯ liá»‡u
    test_percent = 0
    train_percent = 0
    indices_percent = 0

    X_train_initial = np.array([]).reshape(0, 0)
    X_test_data = np.array([]).reshape(0, 0)
    X_indices_data = np.array([]).reshape(0, 0)
    y_train_initial = np.array([])

    # Äá»c dá»¯ liá»‡u
    X, y = load_mnist_data()
    total_samples = X.shape[0] 
    
    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n
    num_samples = st.number_input("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n:", 100, total_samples, 20000)
    
    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Val/Test/Indices
    
    test_size = st.number_input("Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    size = 100 - test_size
    val_size = st.number_input("Chá»n % tá»· lá»‡ táº­p Validation (trong pháº§n cÃ²n láº¡i sau Test)", min_value=10, max_value=size, value=20, step=5)
    train_size = st.number_input("Tá»· lá»‡ dá»¯ liá»‡u táº­p train (%):", 1, 5, 1, step=1)

    # TÃ­nh tá»· lá»‡ indices (pháº§n cÃ²n láº¡i)
    remaining_percent = 100 - test_size  # Pháº§n cÃ²n láº¡i sau khi láº¥y táº­p test
    val_actual_size = (val_size / 100) * remaining_percent  # Tá»· lá»‡ thá»±c táº¿ cá»§a táº­p validation
    train_actual_size = train_size  # Tá»· lá»‡ táº­p train (1-5%)
    indices_size = 100 - test_size - val_actual_size - train_actual_size  # Tá»· lá»‡ táº­p indices

    # Kiá»ƒm tra tá»•ng tá»· lá»‡
    total_percent = train_actual_size + val_actual_size + test_size + indices_size
    if abs(total_percent - 100) > 0.01:  # Kiá»ƒm tra tá»•ng tá»· lá»‡ cÃ³ báº±ng 100% khÃ´ng
        st.error(f"âš ï¸ Tá»•ng tá»· lá»‡ khÃ´ng báº±ng 100%! Hiá»‡n táº¡i: {total_percent:.2f}%")
        return

    st.write(f"**Tá»· lá»‡ phÃ¢n chia:** Train={train_actual_size:.2f}%, Validation={val_actual_size:.2f}%, Test={test_size:.2f}%, Indices={indices_size:.2f}%")

    # Táº¡o nÃºt "LÆ°u Dá»¯ Liá»‡u"
    if st.button("XÃ¡c Nháº­n & LÆ°u Dá»¯ Liá»‡u"):
        # Chá»n sá»‘ lÆ°á»£ng máº«u theo num_samples
        if num_samples == total_samples:
            X_selected = X
            y_selected = y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples/total_samples, stratify=y, random_state=42
            )
        
        # Chia táº­p test
        X_temp, X_test_data, y_temp, y_test_data = train_test_split(
            X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42
        )

        # TÃ­nh sá»‘ lÆ°á»£ng máº«u cho táº­p train dá»±a trÃªn train_size
        remaining_samples = len(X_temp)
        train_samples = int(remaining_samples * (train_actual_size / (100 - test_size)))

        # Láº¥y dá»¯ liá»‡u Ä‘á»u cho má»—i class Ä‘á»ƒ táº¡o táº­p train
        indices = []
        for i in range(10):
            class_indices = np.where(y_temp == i)[0]
            num_samples_per_class = int(train_samples / 10)  # Chia Ä‘á»u cho 10 class
            if num_samples_per_class == 0:  # Äáº£m báº£o Ã­t nháº¥t 1 máº«u má»—i class náº¿u dá»¯ liá»‡u quÃ¡ Ã­t
                num_samples_per_class = 1
            if num_samples_per_class > len(class_indices):  # Náº¿u sá»‘ máº«u yÃªu cáº§u lá»›n hÆ¡n sá»‘ máº«u cÃ³ sáºµn
                num_samples_per_class = len(class_indices)
            data_indices_random = np.random.choice(class_indices, num_samples_per_class, replace=False)
            indices.extend(data_indices_random)

        # Táº¡o táº­p train ban Ä‘áº§u
        X_train_initial = X_temp[indices]
        y_train_initial = y_temp[indices]

        # Pháº§n cÃ²n láº¡i sau khi láº¥y táº­p train
        remaining_indices = np.setdiff1d(np.arange(len(X_temp)), indices)
        X_remaining = X_temp[remaining_indices]
        y_remaining = y_temp[remaining_indices]

        # Chia pháº§n cÃ²n láº¡i thÃ nh táº­p validation vÃ  táº­p indices
        X_val_data, X_indices_data, y_val_data, y_indices_data = train_test_split(
            X_remaining, y_remaining, test_size=indices_size/(100 - test_size - train_actual_size), stratify=y_remaining, random_state=42
        )

        # LÆ°u dá»¯ liá»‡u vÃ o session_state
        st.session_state["X_train"] = X_train_initial
        st.session_state["y_train"] = y_train_initial
        st.session_state["X_val"] = X_val_data
        st.session_state["y_val"] = y_val_data
        st.session_state["X_test"] = X_test_data
        st.session_state["y_test"] = y_test_data
        st.session_state["X_indices"] = X_indices_data
        st.session_state["y_indices"] = y_indices_data

        # Hiá»ƒn thá»‹ káº¿t quáº£
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test", "Indices"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train_initial.shape[0], X_val_data.shape[0], X_test_data.shape[0], X_indices_data.shape[0]]
        })
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)

# def data_preparation():

#     # Cho phÃ©p ngÆ°á»i dÃ¹ng chá»n tá»· lá»‡ validation vÃ  test
#     st.title("Chia dá»¯ liá»‡u Train/Test")
    
#     # Táº¡o cÃ¡c biáº¿n Ä‘á»ƒ lÆ°u dá»¯ liá»‡u

#     test_percent = 0
#     train_percent = 0
#     indices_percent = 0

#     X_train_initial = np.array([]).reshape(0,0)
#     X_test_data = np.array([]).reshape(0,0)
#     X_indices_data = np.array([]).reshape(0,0)
#     y_train_initial = np.array([])

    
    
#     # Äá»c dá»¯ liá»‡u
#     X, y = load_mnist_data()
#     total_samples = X.shape[0] 
    
#     # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
#     num_samples = st.number_input("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n:", 100, total_samples, 20000)
    
#     # if num_samples == total_samples:
#     #     num_samples = num_samples - 10
#     # else:
#     #     num_samples = num_samples

#     # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
#     test_size = st.slider("Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
#     val_size = st.slider("Chá»n % tá»· lá»‡ táº­p Validation (trong pháº§n train)", min_value=10, max_value=50, value=20, step=5)
#     train_size = st.slider("Tá»· lá»‡ dá»¯ liá»‡u táº­p train (%):", 1, 5, 1, step=1)
#     indices_size = 100 - test_size - val_size - train_size

#     st.write(f"**Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation = {val_size}%, Indices={indices_size}%, Train={train_size}%")
#     # chia thÃªm pháº§n dá»¯ liá»‡u táº­p val

    
#     # Táº¡o nÃºt "LÆ°u Dá»¯ Liá»‡u"
#     if st.button("XÃ¡c Nháº­n & LÆ°u Dá»¯ Liá»‡u"):

#         if num_samples == total_samples:
#             X_selected = X
#             y_selected = y
#         else:
#             X_selected, _, y_selected, _ = train_test_split(
#                 X, y, train_size=num_samples/total_samples, stratify=y, random_state=42
#             )
        
#         # Chia thÃ nh táº­p train, val, test
#         X_temp, X_test_data, y_temp, y_test_data = train_test_split(
#             X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42
#         )
#         X_train_data, X_val_data, y_train_data, y_val_data = train_test_split(
#             X_temp, y_temp, test_size=val_size/(100 - test_size), stratify=y_temp, random_state=42
#         )
        
#         # Láº¥y 1% sá»‘ lÆ°á»£ng áº£nh cho má»—i class (0-9) Ä‘á»ƒ lÃ m táº­p dá»¯ liá»‡u train ban Ä‘áº§u
#         indices = []
#         for i in range(10):
#             class_indices = np.where(y_train_data == i)[0]
#             num_samples_per_class = int(0.01 * len(class_indices))
#             if num_samples_per_class == 0:  # Äáº£m báº£o Ã­t nháº¥t 1 máº«u má»—i class náº¿u dá»¯ liá»‡u quÃ¡ Ã­t
#                 num_samples_per_class = 1
#             data_indices_random = np.random.choice(class_indices, num_samples_per_class, replace=False)
#             indices.extend(data_indices_random)

#         X_train_initial = X_train_data[indices]
#         y_train_initial = y_train_data[indices]

#         # Chuyá»ƒn pháº§n cÃ²n láº¡i (khÃ´ng thuá»™c train_initial) sang táº­p indices
#         data_indices = np.setdiff1d(np.arange(len(X_train_data)), indices)
#         X_indices_data = X_train_data[data_indices]
#         y_indices_data = y_train_data[data_indices]

#         # LÆ°u dá»¯ liá»‡u vÃ o session_state
#         st.session_state["X_train"] = X_train_initial
#         st.session_state["y_train"] = y_train_initial
#         st.session_state["X_val"] = X_val_data
#         st.session_state["y_val"] = y_val_data
#         st.session_state["X_test"] = X_test_data
#         st.session_state["y_test"] = y_test_data
#         st.session_state["X_indices"] = X_indices_data
#         st.session_state["y_indices"] = y_indices_data

#         # Hiá»ƒn thá»‹ káº¿t quáº£
#         summary_df = pd.DataFrame({
#             "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test", "Indices"],
#             "Sá»‘ lÆ°á»£ng máº«u": [X_train_initial.shape[0], X_val_data.shape[0], X_test_data.shape[0], X_indices_data.shape[0]]
#         })
#         st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
#         st.table(summary_df)
        
#         # # Ghi log cho quÃ¡ trÃ¬nh phÃ¢n chia dá»¯ liá»‡u
#         # mlflow.log_param("test_size", test_size)
#         # mlflow.log_metric("test_percent", test_percent)
#         # mlflow.log_metric("train_percent", train_percent)
#         # mlflow.log_metric("val_percent", val_percent)
#         # with result_placeholder:
#         # Hiá»ƒn thá»‹ káº¿t quáº£
        
        



def learning_model():
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return
    if "X_indices" not in st.session_state:
        st.error("âš ï¸ Dá»¯ liá»‡u X_indices khÃ´ng tá»“n táº¡i! Vui lÃ²ng kiá»ƒm tra bÆ°á»›c chuáº©n bá»‹ dá»¯ liá»‡u.")
        return
        
    # Láº¥y dá»¯ liá»‡u tá»« session_state
    X_train = st.session_state["X_train"]
    X_indices = st.session_state["X_indices"]
    X_test = st.session_state["X_test"]
    X_val = st.session_state["X_val"]
    y_train = st.session_state["y_train"]
    y_indices = st.session_state["y_indices"]
    y_test = st.session_state["y_test"]
    y_val = st.session_state["y_val"]

    run_name = st.text_input("Nháº­p tÃªn Run:", "")
    # Lá»±a chá»n tham sá»‘ huáº¥n luyá»‡n
    st.markdown("### Lá»±a chá»n tham sá»‘ huáº¥n luyá»‡n")
    
    # Chia giao diá»‡n thÃ nh 2 cá»™t
    col1, col2 = st.columns(2)

    # Cá»™t 1: k_folds, num_layers, epochs
    with col1:
        st.markdown("### Chá»‰ Sá»‘ Model Neural Network")
        k_folds = st.number_input("Sá»‘ fold cho Cross-Validation:", 3, 10, 5)
        num_layers = st.number_input("Sá»‘ lá»›p áº©n:", 1, 5, 2)
        epochs = st.number_input("Sá»‘ láº§n láº·p tá»‘i Ä‘a", 2, 50, 5)
        learning_rate = st.number_input("Tá»‘c Ä‘á»™ há»c", 0.001, 0.1, 0.01, step=0.001, format="%.3f")
        activation = st.selectbox("HÃ m kÃ­ch hoáº¡t:", ["relu", "sigmoid", "tanh"])
        num_neurons = st.selectbox("Sá»‘ neuron má»—i lá»›p:", [32, 64, 128, 256], index=0)
        optimizer = st.selectbox("Chá»n hÃ m tá»‘i Æ°u", ["adam", "sgd", "lbfgs"])

    # Cá»™t 2: learning_rate_init, activation, num_neurons, optimizer
    with col2:
        st.markdown("### Chá»‰ Sá»‘ Thá»±c Hiá»‡n Pseudo-labeling")
        max_iterations = st.number_input("Sá»‘ vÃ²ng láº·p tá»‘i Ä‘a cho pseudo-labeling:", 1, 10, 3)
        threshold = st.number_input("Threshold", min_value=0.0, max_value=1.0, value=0.6, step=0.01)
    loss_fn = "sparse_categorical_crossentropy"
    
    st.session_state['run_name'] = run_name
    
    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        with st.spinner("Äang huáº¥n luyá»‡n..."):
            with mlflow.start_run(run_name=run_name):

                X_unlabeled = X_indices.copy()
                unlabeled_indices = np.arange(len(X_indices))
                iteration = 0
                overall_progress = st.progress(0)
                total_start_time = time.time()

                while len(X_unlabeled) > 0 and iteration < max_iterations:
                    iteration += 1
                    st.write(f"ğŸ”„ VÃ²ng láº·p pseudo-labeling thá»© {iteration}")

                    # Sá»‘ lÆ°á»£ng dá»¯ liá»‡u táº­p train trÆ°á»›c khi thÃªm dá»¯ liá»‡u má»›i
                    train_size_before = len(X_train)

                    # Chuáº©n bá»‹ dá»¯ liá»‡u validation cá»‘ Ä‘á»‹nh
                    X_val_flat = X_val.reshape(-1, 28 * 28).astype('float32') / 255.0

                    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
                    accuracies, losses = [], []
                    training_progress = st.progress(0)
                    training_status = st.empty()

                    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh
                    model = keras.Sequential([
                            layers.Input(shape=(28 * 28,))
                        ] + [layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)
                        ] + [layers.Dense(10, activation="softmax")])

                    if optimizer == "adam":
                        opt = keras.optimizers.Adam(learning_rate=learning_rate)
                    elif optimizer == "sgd":
                        opt = keras.optimizers.SGD(learning_rate=learning_rate)
                    else:
                        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)

                    # Biáº¿n Ä‘á»ƒ lÆ°u lá»‹ch sá»­ huáº¥n luyá»‡n tá»•ng há»£p qua táº¥t cáº£ cÃ¡c fold
                    full_history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}
                    total_time = 0  # Theo dÃµi tá»•ng thá»i gian huáº¥n luyá»‡n

                    # Cross-validation
                    for fold_idx, (train_idx, _) in enumerate(kf.split(X_train, y_train)):
                        # Kiá»ƒm tra vÃ  sá»­a lá»—i khi truy cáº­p X_train[train_idx]
                        if len(train_idx) == 0 or len(X_train) == 0:
                            st.error(f"âš ï¸ Lá»—i: Táº­p train trá»‘ng trong fold {fold_idx + 1}")
                            mlflow.end_run()
                            return
                        try:
                            X_k_train = X_train[train_idx]
                            y_k_train = y_train[train_idx]
                        except IndexError as e:
                            st.error(f"âš ï¸ Lá»—i chá»‰ sá»‘ trong fold {fold_idx + 1}: {str(e)}")
                            st.write(f"KÃ­ch thÆ°á»›c X_train: {X_train.shape}, train_idx: {train_idx}")
                            mlflow.end_run()
                            return

                        X_k_train_flat = X_k_train.reshape(-1, 28 * 28).astype('float32') / 255.0
                        
                        if fold_idx == 0:
                            model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])
                        try:
                            start_time = time.time()
                            history = model.fit(X_k_train_flat, y_k_train, epochs=epochs, 
                                            validation_data=(X_val_flat, y_val), verbose=0)
                            accuracies.append(history.history["val_accuracy"][-1])
                            losses.append(history.history["val_loss"][-1])
                            elapsed_time = time.time() - start_time
                            total_time += elapsed_time

                            # Gá»™p lá»‹ch sá»­ huáº¥n luyá»‡n tá»« fold hiá»‡n táº¡i vÃ o full_history
                            full_history['loss'].extend(history.history['loss'])
                            full_history['accuracy'].extend(history.history['accuracy'])
                            full_history['val_loss'].extend(history.history['val_loss'])
                            full_history['val_accuracy'].extend(history.history['val_accuracy'])

                            # LÆ°u trá»¯ Ä‘á»™ chÃ­nh xÃ¡c vÃ  loss cá»§a fold hiá»‡n táº¡i Ä‘á»ƒ tÃ­nh trung bÃ¬nh
                            accuracies.append(history.history["val_accuracy"][-1])
                            losses.append(history.history["val_loss"][-1])

                            

                        except Exception as e:
                            st.error(f"Training failed in fold {fold_idx + 1}: {str(e)}")
                            mlflow.end_run()
                            return

                        progress_percent = int(((fold_idx + 1) / k_folds) * 100)
                        training_progress.progress(progress_percent)
                        training_status.text(f"â³ Äang huáº¥n luyá»‡n... {progress_percent}%")

                    avg_val_accuracy = np.mean(accuracies)

                    mlflow.log_metrics({
                        f"iter_{iteration}_avg_val_accuracy": avg_val_accuracy,
                        f"iter_{iteration}_avg_val_loss": np.mean(losses)
                    })

                    # TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p test
                    X_test_flat = X_test.reshape(-1, 28 * 28).astype('float32') / 255.0
                    test_loss, test_accuracy = model.evaluate(X_test_flat, y_test, verbose=0)

                    st.write(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p Test sau vÃ²ng láº·p {iteration}: {test_accuracy:.4f}")

                    mlflow.log_metric(f"iter_{iteration}_test_accuracy", test_accuracy)
                    mlflow.log_metric(f"iter_{iteration}_test_loss", test_loss)

                    # GÃ¡n nhÃ£n giáº£
                    X_unlabeled_flat = X_unlabeled.reshape(-1, 28 * 28).astype('float32') / 255.0
                    predictions = model.predict(X_unlabeled_flat, verbose=0)
                    confidence_scores = np.max(predictions, axis=1)
                    pseudo_labels = np.argmax(predictions, axis=1)

                    confident_mask = confidence_scores >= threshold


                    if np.sum(confident_mask) > 0:
                        X_confident = X_unlabeled[confident_mask]
                        y_confident = pseudo_labels[confident_mask]
                        # Láº¥y chá»‰ sá»‘ cá»§a cÃ¡c máº«u Ä‘Æ°á»£c chá»n trong X_unlabeled
                        selected_unlabeled_indices = unlabeled_indices[confident_mask]
                        # Láº¥y nhÃ£n tháº­t tá»« y_indices dá»±a trÃªn chá»‰ sá»‘
                        true_labels = y_indices[selected_unlabeled_indices]

                        # TÃ­nh sá»‘ lÆ°á»£ng dá»¯ liá»‡u gÃ¡n nhÃ£n Ä‘Ãºng vÃ  sai
                        num_labeled = len(X_confident)  # Sá»‘ lÆ°á»£ng dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n nhÃ£n
                        num_correct = np.sum(y_confident == true_labels)  # Sá»‘ lÆ°á»£ng gÃ¡n nhÃ£n Ä‘Ãºng
                        num_incorrect = num_labeled - num_correct  # Sá»‘ lÆ°á»£ng gÃ¡n nhÃ£n sai

                        # Táº¡o báº£ng hiá»ƒn thá»‹
                        summary_df = pd.DataFrame({
                            "ThÃ´ng tin": ["Sá»‘ lÆ°á»£ng dá»¯ liá»‡u táº­p train", "Sá»‘ lÆ°á»£ng dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n nhÃ£n", 
                                          "Sá»‘ lÆ°á»£ng dá»¯ liá»‡u gÃ¡n nhÃ£n Ä‘Ãºng", "Sá»‘ lÆ°á»£ng dá»¯ liá»‡u gÃ¡n nhÃ£n sai"],
                            "GiÃ¡ trá»‹": [train_size_before, num_labeled, num_correct, num_incorrect]
                        })
                        st.markdown(f"#### Káº¿t quáº£ gÃ¡n nhÃ£n giáº£ vÃ²ng láº·p {iteration}")
                        st.table(summary_df)

                        X_train = np.concatenate([X_train, X_confident])
                        y_train = np.concatenate([y_train, y_confident])
                        # Cáº­p nháº­t X_unlabeled vÃ  unlabeled_indices
                        X_unlabeled = X_unlabeled[~confident_mask]
                        unlabeled_indices = unlabeled_indices[~confident_mask]
                        st.write(f"âœ… ÄÃ£ thÃªm {np.sum(confident_mask)} máº«u vÃ o táº­p huáº¥n luyá»‡n")
                        st.write(f"Äá»™ ChÃ­nh XÃ¡c (Validation): {avg_val_accuracy:.4f}")

                        # Hiá»ƒn thá»‹ ngáº«u nhiÃªn 5 máº«u áº£nh vá»«a Ä‘Æ°á»£c gÃ¡n nhÃ£n giáº£
                        st.markdown("#### Má»™t sá»‘ máº«u vá»«a Ä‘Æ°á»£c gÃ¡n nhÃ£n giáº£")
                        if len(X_confident) >= 5:
                            # Chá»n ngáº«u nhiÃªn 5 máº«u tá»« X_confident
                            indices = np.random.choice(len(X_confident), 5, replace=False)
                            selected_images = X_confident[indices]
                            selected_pseudo_labels = y_confident[indices]
                            selected_true_labels = true_labels[indices]
                        else:
                            # Náº¿u sá»‘ máº«u Ã­t hÆ¡n 5, láº¥y táº¥t cáº£ máº«u
                            selected_images = X_confident
                            selected_pseudo_labels = y_confident
                            selected_true_labels = true_labels

                        # Chia giao diá»‡n thÃ nh 5 cá»™t Ä‘á»ƒ hiá»ƒn thá»‹ 5 áº£nh
                        cols = st.columns(5)
                        for i in range(min(5, len(selected_images))):
                            with cols[i]:
                                # Äáº£m báº£o áº£nh cÃ³ Ä‘á»‹nh dáº¡ng Ä‘Ãºng (28x28) vÃ  giÃ¡ trá»‹ tá»« 0-255
                                image = selected_images[i]
                                # .reshape(28, 28) * 255.0
                                # image = image.astype(np.uint8)
                                # Hiá»ƒn thá»‹ áº£nh vá»›i nhÃ£n giáº£ vÃ  nhÃ£n tháº­t
                                st.image(image, caption=f"NhÃ£n giáº£: {selected_pseudo_labels[i]} | NhÃ£n tháº­t: {selected_true_labels[i]}", use_container_width=True)
                    else:
                        st.write(f"âš ï¸ KhÃ´ng cÃ³ máº«u nÃ o Ä‘áº¡t ngÆ°á»¡ng tin cáº­y {threshold}. Káº¿t thÃºc sá»›m.")
                        break  # ThoÃ¡t vÃ²ng láº·p náº¿u khÃ´ng cÃ³ máº«u nÃ o Ä‘Æ°á»£c gÃ¡n nhÃ£n

                    overall_progress.progress(min(iteration / max_iterations, 1.0))

                    # Ghi log vÃ o MLFlow
                    
                    mlflow.log_param("k_folds", k_folds)
                    mlflow.log_param("num_layers", num_layers)
                    mlflow.log_param("epochs", epochs)
                    mlflow.log_param("learning_rate_init", learning_rate)
                    mlflow.log_param("activation", activation)
                    mlflow.log_param("num_neurons", num_neurons)
                    mlflow.log_param("optimizer", optimizer)
                    mlflow.log_param("loss_function", loss_fn)
                    mlflow.log_metric("train_accuracy", full_history['accuracy'][-1])
                    mlflow.log_metric("val_accuracy", full_history['val_accuracy'][-1])
                    mlflow.log_metric("final_train_loss", full_history['loss'][-1])
                    mlflow.log_metric("final_val_loss", full_history['val_loss'][-1])

            # Huáº¥n luyá»‡n láº¡i trÃªn toÃ n bá»™ dá»¯ liá»‡u Ä‘á»ƒ cÃ³ mÃ´ hÃ¬nh cuá»‘i cÃ¹ng
            X_train_flat = X_train.reshape(-1, 28 * 28).astype('float32') / 255.0
            model.fit(X_train_flat, y_train, epochs=epochs, verbose=0)

            # TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng trÃªn táº­p test
            X_test_flat = X_test.reshape(-1, 28 * 28).astype('float32') / 255.0
            final_test_loss, final_test_accuracy = model.evaluate(X_test_flat, y_test, verbose=0)

            mlflow.log_metric("final_test_accuracy", final_test_accuracy)
            mlflow.log_metric("final_test_loss", final_test_loss)

            total_elapsed_time = time.time() - total_start_time
            mlflow.log_metrics({"total_elapsed_time": total_elapsed_time})
            mlflow.end_run()

            # LÆ°u mÃ´ hÃ¬nh
            st.session_state["trained_model"] = model

            st.success(f"âœ… QuÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  gÃ¡n nhÃ£n giáº£ hoÃ n táº¥t!")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh cuá»‘i cÃ¹ng trÃªn táº­p validation:** {avg_val_accuracy:.4f}")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng trÃªn táº­p test:** {final_test_accuracy:.4f}")
            st.write(f"â±ï¸ **Tá»•ng thá»i gian huáº¥n luyá»‡n:** {total_elapsed_time:.2f} giÃ¢y")
            st.write(f"ğŸ“ˆ **Sá»‘ máº«u trong táº­p huáº¥n luyá»‡n cuá»‘i cÃ¹ng:** {len(X_train)}")




def run_PseudoLabelling_app():

    mlflow_tracking_uri = st.secrets["MLFLOW_TRACKING_URI"]
    mlflow_username = st.secrets["MLFLOW_TRACKING_USERNAME"]
    mlflow_password = st.secrets["MLFLOW_TRACKING_PASSWORD"]
    
    # Thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng
    os.environ["MLFLOW_TRACKING_URI"] = mlflow_tracking_uri
    os.environ["MLFLOW_TRACKING_USERNAME"] = mlflow_username
    os.environ["MLFLOW_TRACKING_PASSWORD"] = mlflow_password
    
    # Thiáº¿t láº­p MLflow (Äáº·t sau khi mlflow_tracking_uri Ä‘Ã£ cÃ³ giÃ¡ trá»‹)
    mlflow.set_tracking_uri(mlflow_tracking_uri)




    # Giao diá»‡n Streamlit
    st.title("ğŸ“¸ PhÃ¢n loáº¡i áº£nh MNIST vá»›i Streamlit")
    tabs = st.tabs([
        "ThÃ´ng tin dá»¯ liá»‡u",
        "ThÃ´ng tin",
        "Xá»­ lÃ­ dá»¯ liá»‡u",
        "Huáº¥n luyá»‡n mÃ´ hÃ¬nh",
        "Demo dá»± Ä‘oÃ¡n file áº£nh",
        "Demo dá»± Ä‘oÃ¡n Viáº¿t Tay",
        "ThÃ´ng tin & Mlflow",
    ])
    # tab_info, tab_load, tab_preprocess, tab_split,  tab_demo, tab_log_info = tabs
    tab_info,tab_note,tab_load, tab_preprocess,  tab_demo, tab_demo_2 ,tab_mlflow= tabs

    # with st.expander("ğŸ–¼ï¸ Dá»¯ liá»‡u ban Ä‘áº§u", expanded=True):
    with tab_info:
        with st.expander("**ThÃ´ng tin dá»¯ liá»‡u**", expanded=True):
            st.markdown(
                '''
                **MNIST** lÃ  phiÃªn báº£n Ä‘Æ°á»£c chá»‰nh sá»­a tá»« bá»™ dá»¯ liá»‡u NIST gá»‘c cá»§a Viá»‡n TiÃªu chuáº©n vÃ  CÃ´ng nghá»‡ Quá»‘c gia Hoa Ká»³.  
                Bá»™ dá»¯ liá»‡u ban Ä‘áº§u gá»“m cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« nhÃ¢n viÃªn bÆ°u Ä‘iá»‡n vÃ  há»c sinh trung há»c.  

                CÃ¡c nhÃ  nghiÃªn cá»©u **Yann LeCun, Corinna Cortes, vÃ  Christopher Burges** Ä‘Ã£ xá»­ lÃ½, chuáº©n hÃ³a vÃ  chuyá»ƒn Ä‘á»•i bá»™ dá»¯ liá»‡u nÃ y thÃ nh **MNIST** Ä‘á»ƒ dá»… dÃ ng sá»­ dá»¥ng hÆ¡n cho cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay.
                '''
            )
            # image = Image.open(r'C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\App\image.png')
            X_Information, y_Information = load_mnist_data()
            # Gáº¯n áº£nh vÃ o Streamlit vÃ  chá»‰nh kÃ­ch thÆ°á»›c
            # st.image(image, caption='MÃ´ táº£ áº£nh', width=600) 
            # Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u
        with st.expander("**Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u**", expanded=True):
            st.markdown(
                '''
                - **Sá»‘ lÆ°á»£ng áº£nh:** 70.000 áº£nh chá»¯ sá»‘ viáº¿t tay  
                - **KÃ­ch thÆ°á»›c áº£nh:** Má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c 28x28 pixel  
                - **CÆ°á»ng Ä‘á»™ Ä‘iá»ƒm áº£nh:** Tá»« 0 (mÃ u Ä‘en) Ä‘áº¿n 255 (mÃ u tráº¯ng)  
                - **Dá»¯ liá»‡u nhÃ£n:** Má»—i áº£nh Ä‘i kÃ¨m vá»›i má»™t nhÃ£n sá»‘ tá»« 0 Ä‘áº¿n 9  
                '''
            )

        with st.expander("**Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9 trong táº­p huáº¥n luyá»‡n**", expanded=True):
            label_counts = pd.Series(y_Information).value_counts().sort_index()

            # # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ cá»™t
            st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng chá»¯ sá»‘")
            st.bar_chart(label_counts)

            # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u dÆ°á»›i biá»ƒu Ä‘á»“
            st.subheader("ğŸ“‹ Sá»‘ lÆ°á»£ng máº«u cho tá»«ng chá»¯ sá»‘")
            df_counts = pd.DataFrame({"Chá»¯ sá»‘": label_counts.index, "Sá»‘ lÆ°á»£ng máº«u": label_counts.values})
            st.dataframe(df_counts)


            st.subheader("Chá»n ngáº«u nhiÃªn 10 áº£nh tá»« táº­p huáº¥n luyá»‡n Ä‘á»ƒ hiá»ƒn thá»‹")
            num_images = 10
            random_indices = random.sample(range(len(y_Information)), num_images)
            fig, axes = plt.subplots(1, num_images, figsize=(10, 5))

            for ax, idx in zip(axes, random_indices):
                ax.imshow(X_Information[idx], cmap='gray')
                ax.axis("off")
                ax.set_title(f"Label: {y_Information[idx]}")

            st.pyplot(fig)
        with st.expander("**Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u**", expanded=True):    
            # Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u
            st.write("ğŸ” HÃ¬nh dáº¡ng táº­p huáº¥n luyá»‡n:", X_Information.shape)
            



    with tab_note:
        with st.expander("**ThÃ´ng tin mÃ´ hÃ¬nh**", expanded=True):
            st.markdown("### Chá»n thÃ´ng tin hiá»ƒn thá»‹ vá» mÃ´ hÃ¬nh")
            model_option = st.selectbox(
                "Chá»n mÃ´ hÃ¬nh:",
                ["Neural Network (NN)", "PseudoLabelling"]
            )

            if model_option == "Neural Network (NN)":
                st.markdown("""
                    ### Neural Network (NN)
                    """) 
                st.markdown("---")        
                st.markdown("""            
                ### KhÃ¡i Niá»‡m:  
                **Neural Network (NN)**:
                - LÃ  má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n láº¥y cáº£m há»©ng tá»« cáº¥u trÃºc vÃ  chá»©c nÄƒng cá»§a máº¡ng lÆ°á»›i tháº§n kinh sinh há»c. NÃ³ Ä‘Æ°á»£c táº¡o thÃ nh tá»« cÃ¡c nÃºt káº¿t ná»‘i vá»›i nhau, hay cÃ²n gá»i lÃ  nÆ¡-ron nhÃ¢n táº¡o, Ä‘Æ°á»£c sáº¯p xáº¿p thÃ nh cÃ¡c lá»›p.
                - Ã tÆ°á»Ÿng chÃ­nh cá»§a **Neural Network** lÃ  táº¡o ra má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n cÃ³ kháº£ nÄƒng há»c há»i vÃ  xá»­ lÃ½ thÃ´ng tin giá»‘ng nhÆ° bá»™ nÃ£o con ngÆ°á»i.
                """)
                

                st.markdown("---")        
                st.write("### MÃ´ HÃ¬nh Tá»•ng QuÃ¡t:")   
                st.image("imgnn/modelnn.png", use_container_width="auto", caption="MÃ´ hÃ¬nh Neural Network (machinelearningcoban.com)")
                st.markdown(""" 
                - Layer Ä‘áº§u tiÃªn lÃ  input layer, cÃ¡c layer á»Ÿ giá»¯a Ä‘Æ°á»£c gá»i lÃ  hidden layer, layer cuá»‘i cÃ¹ng Ä‘Æ°á»£c gá»i lÃ  output layer. CÃ¡c hÃ¬nh trÃ²n Ä‘Æ°á»£c gá»i lÃ  node.
                - Má»—i mÃ´ hÃ¬nh luÃ´n cÃ³ 1 input layer, 1 output layer, cÃ³ thá»ƒ cÃ³ hoáº·c khÃ´ng cÃ¡c hidden layer. Tá»•ng sá»‘ layer trong mÃ´ hÃ¬nh Ä‘Æ°á»£c quy Æ°á»›c lÃ  sá»‘ layer - 1 (KhÃ´ng tÃ­nh input layer).
                - Má»—i node trong hidden layer vÃ  output layer :
                    - LiÃªn káº¿t vá»›i táº¥t cáº£ cÃ¡c node á»Ÿ layer trÆ°á»›c Ä‘Ã³ vá»›i cÃ¡c há»‡ sá»‘ w riÃªng.
                    - Má»—i node cÃ³ 1 há»‡ sá»‘ bias b riÃªng.
                    - Diá»…n ra 2 bÆ°á»›c: tÃ­nh tá»•ng linear vÃ  Ã¡p dá»¥ng activation function.
                """)


                st.markdown("---")          
                st.markdown("""
                ### NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng:  
                - Dá»¯ liá»‡u Ä‘áº§u vÃ o Ä‘Æ°á»£c Ä‘Æ°a vÃ o lá»›p Ä‘áº§u vÃ o.
                - Má»—i nÆ¡-ron trong lá»›p áº©n nháº­n tÃ­n hiá»‡u tá»« cÃ¡c nÆ¡-ron á»Ÿ lá»›p trÆ°á»›c Ä‘Ã³, xá»­ lÃ½ tÃ­n hiá»‡u vÃ  chuyá»ƒn tiáº¿p káº¿t quáº£ Ä‘áº¿n cÃ¡c nÆ¡-ron á»Ÿ lá»›p tiáº¿p theo.
                - QuÃ¡ trÃ¬nh nÃ y tiáº¿p tá»¥c cho Ä‘áº¿n khi dá»¯ liá»‡u Ä‘áº¿n lá»›p Ä‘áº§u ra.
                - Káº¿t quáº£ Ä‘áº§u ra Ä‘Æ°á»£c táº¡o ra dá»±a trÃªn cÃ¡c tÃ­n hiá»‡u nháº­n Ä‘Æ°á»£c tá»« lá»›p áº©n cuá»‘i cÃ¹ng.
                """)           
                st.markdown("---")
                st.markdown("""  
                ### Ãp dá»¥ng vÃ o ngá»¯ cáº£nh Neural Network vá»›i MNIST:  
                - **MNIST (Modified National Institute of Standards and Technology database)** lÃ  má»™t bá»™ dá»¯ liá»‡u kinh Ä‘iá»ƒn trong lÄ©nh vá»±c há»c mÃ¡y, Ä‘áº·c biá»‡t lÃ  trong viá»‡c Ã¡p dá»¥ng máº¡ng nÆ¡-ron. NÃ³ bao gá»“m 70.000 áº£nh xÃ¡m cá»§a chá»¯ sá»‘ viáº¿t tay (tá»« 0 Ä‘áº¿n 9), Ä‘Æ°á»£c chia thÃ nh 60.000 áº£nh huáº¥n luyá»‡n vÃ  10.000 áº£nh kiá»ƒm tra.
                - Má»¥c tiÃªu cá»§a bÃ i toÃ¡n lÃ  phÃ¢n loáº¡i chÃ­nh xÃ¡c chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9 dá»±a trÃªn áº£nh Ä‘áº§u vÃ o.
                - CÃ³ nhiá»u cÃ¡ch Ä‘á»ƒ Ã¡p dá»¥ng máº¡ng nÆ¡-ron cho bÃ i toÃ¡n phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay trÃªn MNIST. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ phÆ°Æ¡ng phÃ¡p phá»• biáº¿n:
                    - **Multi-Layer Perceptron (MLP)**: Má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sÃ¢u vá»›i nhiá»u lá»›p áº©n.
                    - **Convolutional Neural Network (CNN)**: Má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sÃ¢u Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho viá»‡c xá»­ lÃ½ áº£nh.
                    - **Recurrent Neural Network (RNN)**: Má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sÃ¢u Ä‘Æ°á»£c thiáº¿t káº¿ cho dá»¯ liá»‡u chuá»—i.
                """)

            elif model_option == "PseudoLabelling":
                st.markdown("""
                    ### PseudoLabelling
                    """)
                st.markdown("---")
                
                st.markdown("""
                ### KhÃ¡i Niá»‡m:
                **PseudoLabelling**:
                - LÃ  má»™t ká»¹ thuáº­t há»c bÃ¡n giÃ¡m sÃ¡t (semi-supervised learning) nháº±m táº­n dá»¥ng cáº£ dá»¯ liá»‡u cÃ³ nhÃ£n vÃ  dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh há»c mÃ¡y.
                - Ã tÆ°á»Ÿng chÃ­nh lÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u cÃ³ nhÃ£n Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n cho dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n, sau Ä‘Ã³ thÃªm cÃ¡c nhÃ£n "giáº£" (pseudo-labels) nÃ y vÃ o táº­p huáº¥n luyá»‡n Ä‘á»ƒ tiáº¿p tá»¥c huáº¥n luyá»‡n mÃ´ hÃ¬nh.
                """)

                st.markdown("---")        
                st.write("### MÃ´ HÃ¬nh Tá»•ng QuÃ¡t:")   
                st.image("imgpl/modelpl.png", use_container_width="auto", caption="MÃ´ hÃ¬nh PseudoLabelling (researchgate.net)")
                st.markdown("""
                    **Giáº£i thÃ­ch quy trÃ¬nh:**
                    - **Labeled data (Dá»¯ liá»‡u cÃ³ nhÃ£n):** Táº­p dá»¯ liá»‡u ban Ä‘áº§u vá»›i cÃ¡c máº«u Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n (mÃ u Ä‘á» vÃ  xanh dÆ°Æ¡ng Ä‘áº¡i diá»‡n cho cÃ¡c lá»›p khÃ¡c nhau).
                    - **Unlabeled data (Dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n):** Táº­p dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c gÃ¡n nhÃ£n (mÃ u xÃ¡m).
                    - **Train (Huáº¥n luyá»‡n):** MÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u.
                    - **Predict (Dá»± Ä‘oÃ¡n):** MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n nhÃ£n cho dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n.
                    - **Pseudo-labeled data (Dá»¯ liá»‡u nhÃ£n giáº£):** CÃ¡c máº«u khÃ´ng cÃ³ nhÃ£n Ä‘Æ°á»£c gÃ¡n nhÃ£n giáº£ dá»±a trÃªn dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh (mÃ u Ä‘á» vÃ  xanh dÆ°Æ¡ng).
                    - **Append (ThÃªm vÃ o):** Dá»¯ liá»‡u nhÃ£n giáº£ Ä‘Æ°á»£c thÃªm vÃ o táº­p dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u.
                    - **Retrain (Huáº¥n luyá»‡n láº¡i):** MÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n láº¡i trÃªn táº­p dá»¯ liá»‡u má»Ÿ rá»™ng (bao gá»“m cáº£ dá»¯ liá»‡u cÃ³ nhÃ£n vÃ  nhÃ£n giáº£).
                    - QuÃ¡ trÃ¬nh nÃ y láº·p láº¡i Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh.
                    """)

                st.markdown("---")
                st.markdown("""
                ### NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng:
                - **BÆ°á»›c 1:** Huáº¥n luyá»‡n mÃ´ hÃ¬nh ban Ä‘áº§u trÃªn táº­p dá»¯ liá»‡u cÃ³ nhÃ£n (labeled data) báº±ng phÆ°Æ¡ng phÃ¡p há»c cÃ³ giÃ¡m sÃ¡t.
                - **BÆ°á»›c 2:** Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n cho táº­p dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n (unlabeled data).
                - **BÆ°á»›c 3:** Lá»c cÃ¡c dá»± Ä‘oÃ¡n cÃ³ Ä‘á»™ tin cáº­y cao (dá»±a trÃªn ngÆ°á»¡ng xÃ¡c suáº¥t) vÃ  gÃ¡n nhÃ£n giáº£ cho cÃ¡c máº«u nÃ y.
                - **BÆ°á»›c 4:** Káº¿t há»£p dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u vá»›i dá»¯ liá»‡u cÃ³ nhÃ£n giáº£, sau Ä‘Ã³ huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u má»Ÿ rá»™ng.
                - **Láº·p láº¡i:** QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c láº·p láº¡i nhiá»u láº§n cho Ä‘áº¿n khi khÃ´ng cÃ²n máº«u nÃ o Ä‘áº¡t ngÆ°á»¡ng tin cáº­y hoáº·c Ä‘áº¡t sá»‘ vÃ²ng láº·p tá»‘i Ä‘a.
                """)

                st.markdown("---")
                st.markdown("""
                ### Ãp dá»¥ng vÃ o ngá»¯ cáº£nh PseudoLabelling vá»›i MNIST:
                - Trong bÃ i toÃ¡n MNIST, PseudoLabelling Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº­n dá»¥ng táº­p dá»¯ liá»‡u lá»›n nhÆ°ng chá»‰ má»™t pháº§n nhá» cÃ³ nhÃ£n.
                - **Quy trÃ¬nh cá»¥ thá»ƒ:**
                    1. Báº¯t Ä‘áº§u vá»›i má»™t táº­p train nhá» (cÃ³ nhÃ£n) tá»« dá»¯ liá»‡u MNIST (vÃ­ dá»¥: 1% má»—i class).
                    2. Sá»­ dá»¥ng mÃ´ hÃ¬nh Neural Network Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n cho táº­p dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n (indices).
                    3. Chá»n cÃ¡c dá»± Ä‘oÃ¡n cÃ³ Ä‘á»™ tin cáº­y cao (threshold) vÃ  thÃªm vÃ o táº­p train.
                    4. Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh trÃªn táº­p train má»Ÿ rá»™ng vÃ  láº·p láº¡i quÃ¡ trÃ¬nh.
                - **Lá»£i Ã­ch:** Giáº£m sá»± phá»¥ thuá»™c vÃ o dá»¯ liá»‡u cÃ³ nhÃ£n Ä‘áº§y Ä‘á»§, táº­n dá»¥ng tá»‘i Ä‘a dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.
                """)
    
    with tab_load:
        with st.expander("**Táº£i dá»¯ liá»‡u**", expanded=True):
            
            data_preparation()


    # 3ï¸âƒ£ HUáº¤N LUYá»†N MÃ” HÃŒNH
    with tab_preprocess:
        with st.expander("**Huáº¥n luyá»‡n Neural Network**", expanded=True):

            learning_model()

    with tab_demo:   
        with st.expander("**Dá»± Ä‘oÃ¡n káº¿t quáº£**", expanded=True):
            st.write("**Dá»± Ä‘oÃ¡n trÃªn áº£nh do ngÆ°á»i dÃ¹ng táº£i lÃªn**")

            # Kiá»ƒm tra xem mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  lÆ°u chÆ°a
            if "trained_model" not in st.session_state:
                st.warning("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c khi dá»± Ä‘oÃ¡n.")
            else:
                best_model = st.session_state["trained_model"]
                st.write(f"MÃ´ hÃ¬nh Ä‘ang sá»­ dá»¥ng: MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n tá»« `learning_model()`")

                # Cho phÃ©p ngÆ°á»i dÃ¹ng táº£i lÃªn áº£nh
                uploaded_file = st.file_uploader("ğŸ“‚ Chá»n má»™t áº£nh Ä‘á»ƒ dá»± Ä‘oÃ¡n (28x28)", type=["png", "jpg", "jpeg"])

                if uploaded_file is not None:
                    # Äá»c vÃ  tiá»n xá»­ lÃ½ áº£nh
                    image = Image.open(uploaded_file).convert("L")  # Chuyá»ƒn sang áº£nh xÃ¡m
                    image = np.array(image)

                    # Resize áº£nh vá» kÃ­ch thÆ°á»›c 28x28
                    image = cv2.resize(image, (28, 28))

                    # Pháº³ng hÃ³a vÃ  chuáº©n hÃ³a giá»‘ng dá»¯ liá»‡u huáº¥n luyá»‡n
                    image_normalized = image.reshape(1, 28 * 28).astype('float32') / 255.0

                    # Reshape to 1D vector (1, 784) to match training input
                    image_flat = image_normalized.reshape(1, -1)
                    
                    # Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
                    try:
                        prediction = best_model.predict(image_flat, verbose=0)[0]
                        predicted_class = np.argmax(prediction)
                        confidence = np.max(prediction)

                        # Hiá»ƒn thá»‹ áº£nh vÃ  káº¿t quáº£ dá»± Ä‘oÃ¡n
                        st.image(uploaded_file, caption="ğŸ“· áº¢nh báº¡n Ä‘Ã£ táº£i lÃªn", width=200)
                        st.success(f"Dá»± Ä‘oÃ¡n: **{predicted_class}** vá»›i Ä‘á»™ tin cáº­y: **{confidence:.4f}**")

                        # (TÃ¹y chá»n) Hiá»ƒn thá»‹ phÃ¢n phá»‘i xÃ¡c suáº¥t
                        st.write("PhÃ¢n phá»‘i xÃ¡c suáº¥t:")
                        st.bar_chart(prediction)

                    except Exception as e:
                        st.error(f"Lá»—i khi dá»± Ä‘oÃ¡n: {str(e)}. HÃ£y kiá»ƒm tra Ä‘á»‹nh dáº¡ng áº£nh vÃ  mÃ´ hÃ¬nh!")

                else:
                    st.info("Vui lÃ²ng táº£i lÃªn má»™t áº£nh Ä‘á»ƒ dá»± Ä‘oÃ¡n.")

    with tab_demo_2:   
        st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")

        # ğŸ“¥ Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
        if "trained_model" in st.session_state:
            model = st.session_state["trained_model"]
            st.success("âœ… ÄÃ£ sá»­ dá»¥ng mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n!")
        else:
            st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh! HÃ£y huáº¥n luyá»‡n trÆ°á»›c.")


        # ğŸ†• Cáº­p nháº­t key cho canvas khi nháº¥n "Táº£i láº¡i"
        if "key_value" not in st.session_state:
            st.session_state.key_value = str(random.randint(0, 1000000))  

        if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas"):
            st.session_state.key_value = str(random.randint(0, 1000000))  

        # âœï¸ Váº½ sá»‘
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=150,
            width=150,
            drawing_mode="freedraw",
            key=st.session_state.key_value,
            update_streamlit=True
        )

        if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
            img = preprocess_canvas_image(canvas_result)

            if img is not None:
                # Preprocess canvas image
                img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
                img = img.resize((28, 28)).convert("L")  # Resize to 28x28 and convert to grayscale
                img_array = np.array(img, dtype=np.float32)

                # Normalize pixel values to [0, 1] (same as training data)
                img_normalized = img_array / 255.0

                # Reshape to 1D vector (1, 784) to match training input
                img_flat = img_normalized.reshape(1, -1)
                # Dá»± Ä‘oÃ¡n sá»‘
                prediction = model.predict(img_flat)
                predicted_number = np.argmax(prediction, axis=1)[0]
                max_confidence = np.max(prediction)

                st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {predicted_number}")
                st.write(f"ğŸ“Š Má»©c Ä‘á»™ tin cáº­y: {max_confidence:.2%}")

                # Hiá»ƒn thá»‹ báº£ng confidence score
                prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
                prob_df.columns = ["Má»©c Ä‘á»™ tin cáº­y"]
                st.bar_chart(prob_df)

            else:
                st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")

    

    with tab_mlflow:
        st.header("ThÃ´ng tin Huáº¥n luyá»‡n & MLflow UI")
        try:
            client = MlflowClient()
            experiment_name = "PseudoLabelling"
    
            # Kiá»ƒm tra náº¿u experiment Ä‘Ã£ tá»“n táº¡i
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment is None:
                experiment_id = client.create_experiment(experiment_name)
                st.success(f"Experiment má»›i Ä‘Æ°á»£c táº¡o vá»›i ID: {experiment_id}")
            else:
                experiment_id = experiment.experiment_id
                st.info(f"Äang sá»­ dá»¥ng experiment ID: {experiment_id}")
    
            mlflow.set_experiment(experiment_name)
    
            # Truy váº¥n cÃ¡c run trong experiment
            runs = client.search_runs(experiment_ids=[experiment_id])
    
            # 1) Chá»n vÃ  Ä‘á»•i tÃªn Run Name
            st.subheader("Äá»•i tÃªn Run")
            if runs:
                run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}"
                               for run in runs}
                selected_run_id_for_rename = st.selectbox("Chá»n Run Ä‘á»ƒ Ä‘á»•i tÃªn:", 
                                                          options=list(run_options.keys()), 
                                                          format_func=lambda x: run_options[x])
                new_run_name = st.text_input("Nháº­p tÃªn má»›i cho Run:", 
                                             value=run_options[selected_run_id_for_rename].split(" - ")[0])
                if st.button("Cáº­p nháº­t tÃªn Run"):
                    if new_run_name.strip():
                        client.set_tag(selected_run_id_for_rename, "mlflow.runName", new_run_name.strip())
                        st.success(f"ÄÃ£ cáº­p nháº­t tÃªn Run thÃ nh: {new_run_name.strip()}")
                    else:
                        st.warning("Vui lÃ²ng nháº­p tÃªn má»›i cho Run.")
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘Æ°á»£c log.")
    
            # 2) XÃ³a Run
            st.subheader("Danh sÃ¡ch Run")
            if runs:
                selected_run_id_to_delete = st.selectbox("", 
                                                         options=list(run_options.keys()), 
                                                         format_func=lambda x: run_options[x])
                if st.button("XÃ³a Run", key="delete_run"):
                    client.delete_run(selected_run_id_to_delete)
                    st.success(f"ÄÃ£ xÃ³a Run {run_options[selected_run_id_to_delete]} thÃ nh cÃ´ng!")
                    st.experimental_rerun()  # Tá»± Ä‘á»™ng lÃ m má»›i giao diá»‡n
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘á»ƒ xÃ³a.")
    
            # 3) Danh sÃ¡ch cÃ¡c thÃ­ nghiá»‡m
            st.subheader("Danh sÃ¡ch cÃ¡c Run Ä‘Ã£ log")
            if runs:
                selected_run_id = st.selectbox("Chá»n Run Ä‘á»ƒ xem chi tiáº¿t:", 
                                               options=list(run_options.keys()), 
                                               format_func=lambda x: run_options[x])
    
                # 4) Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t cá»§a Run Ä‘Æ°á»£c chá»n
                selected_run = client.get_run(selected_run_id)
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")
    
                st.markdown("### Tham sá»‘ Ä‘Ã£ log")
                st.json(selected_run.data.params)
    
                st.markdown("### Chá»‰ sá»‘ Ä‘Ã£ log")
                st.json(selected_run.data.metrics)
    
                # 5) NÃºt báº¥m má»Ÿ MLflow UI
                st.subheader("Truy cáº­p MLflow UI")
                mlflow_url = "https://dagshub.com/quangdinhhusc/HMVPYTHON.mlflow"
                if st.button("Má»Ÿ MLflow UI"):
                    st.markdown(f'**[Click Ä‘á»ƒ má»Ÿ MLflow UI]({mlflow_url})**')
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘Æ°á»£c log. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
    
        except Exception as e:
            st.error(f"KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i MLflow: {e}")

    


if __name__ == "__main__":
    run_PseudoLabelling_app()